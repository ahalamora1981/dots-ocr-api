
services:
  dots-ocr:
    image: dots-ocr:1.0  # 镜像名称，根据实际情况进行调整，样例为“dots-ocr:1.0”
    container_name: dots-ocr
    ipc: host
    ports:
      - "8000:8000"
    volumes:
      - ./models/dots___ocr:/vllm-workspace/DotsOCR  # 根据实际情况进行调整本地模型地址，样例为“./models/dots___ocr”
    restart: unless-stopped
    entrypoint: ["/bin/bash", "-c"]
    command:
      - |
        export hf_model_path=/vllm-workspace/DotsOCR
        export PYTHONPATH=$$(dirname "$$hf_model_path"):$$PYTHONPATH
        sed -i '/^from vllm\.entrypoints\.cli\.main import main$$/a from DotsOCR import modeling_dots_ocr_vllm' `which vllm`
        vllm serve $$hf_model_path --tensor-parallel-size 1 --gpu-memory-utilization 0.95 --chat-template-content-format string --served-model-name model --trust-remote-code
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              device_ids: ['0']  # GPU设备ID，根据实际情况进行调整，样例为“0”，第一块GPU
              capabilities: [gpu]